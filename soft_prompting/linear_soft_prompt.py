import torch

from soft_prompting import soft_prompts
from soft_prompting.soft_prompts import SoftPrompt


class LinearSoftPrompt(SoftPrompt):
    """
    A soft prompt which is generated by a linear model.
    """

    def __init__(self, soft_prompt_token_count: int, input_size: int, embedding_size: int, device: torch.device = None):
        """
        Creates a linear soft prompt.
        :param soft_prompt_token_count: Number of tokens in the soft prompt.
        :param embedding_size: Size of the embedding to create.
        :param device: Device to create the soft prompt on.
        """
        super().__init__(soft_prompt_token_count)
        self.embedding_size = embedding_size
        self.linear = torch.nn.Linear(input_size, soft_prompt_token_count * embedding_size, device=device)

    def forward(self, soft_prompt_parameters: torch.Tensor):
        # Linear soft prompts are generated by a linear model.
        # The model takes a tensor of shape [batch_count, input_size] and produces a tensor of shape
        # [batch_count, embedding_size * soft_prompt_token_count].
        # The output is then reshaped to [batch_count, soft_prompt_token_count, embedding_size].
        if self.soft_prompt_token_count == 0:
            return torch.empty([soft_prompt_parameters.size(0), 0, self.embedding_size], dtype=torch.float32,
                               device=soft_prompt_parameters.device)
        else:
            return self.linear(soft_prompt_parameters).view(-1, self.soft_prompt_token_count, self.embedding_size)

    @property
    def input_parameter_count(self) -> int:
        return self.linear.in_features

    def get_metadata(self) -> dict:
        return {"soft_prompt_token_count": self.soft_prompt_token_count,
                "input_size": self.input_parameter_count, "embedding_size": self.embedding_size}


class LinearFactory:
    def __call__(self, soft_prompt_token_count: int, input_size: int, embedding_size: int) -> soft_prompts.SoftPrompt:
        return LinearSoftPrompt(soft_prompt_token_count, input_size, embedding_size)
